{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing different validation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import itertools\n",
    "import warnings # To suppress warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we will be using the crime rate data from different communities.The original data set can be found\n",
    "on the UCI machine learning data repository (https://archive.ics.uci.edu/ml/datas\n",
    "ets/Communities+and+Crime+Unnormalized). This data set consists of many attributes of\n",
    "different communities, such as household size, percentage of race of different groups, number\n",
    "of police officers, etc. We will be using a  cleaned dataset for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.88</td>\n",
       "      <td>12.47</td>\n",
       "      <td>21.44</td>\n",
       "      <td>10.93</td>\n",
       "      <td>11.33</td>\n",
       "      <td>...</td>\n",
       "      <td>10.66</td>\n",
       "      <td>53.72</td>\n",
       "      <td>65.29</td>\n",
       "      <td>78.09</td>\n",
       "      <td>89.14</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1845.9</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.85</td>\n",
       "      <td>11.01</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.48</td>\n",
       "      <td>17.18</td>\n",
       "      <td>...</td>\n",
       "      <td>8.30</td>\n",
       "      <td>77.17</td>\n",
       "      <td>71.27</td>\n",
       "      <td>90.22</td>\n",
       "      <td>96.12</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2186.7</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0       11980           3.10          1.37         91.78          6.50   \n",
       "1       23123           2.82          0.80         95.57          3.44   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  ...  \\\n",
       "0         1.88        12.47        21.44        10.93       11.33  ...   \n",
       "1         0.85        11.01        21.30        10.48       17.18  ...   \n",
       "\n",
       "   PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0           10.66             53.72           65.29          78.09   \n",
       "1            8.30             77.17           71.27          90.22   \n",
       "\n",
       "   PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \\\n",
       "0           89.14       6.5   1845.9            9.63                  0.0   \n",
       "1           96.12      10.6   2186.7            3.84                  0.0   \n",
       "\n",
       "   nonViolPerPop  \n",
       "0        1394.59  \n",
       "1        1955.95  \n",
       "\n",
       "[2 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community=pd.read_csv(\"community.csv\")\n",
    "community.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['population' 'householdsize' 'racepctblack' 'racePctWhite' 'racePctAsian'\n",
      " 'racePctHisp' 'agePct12t21' 'agePct12t29' 'agePct16t24' 'agePct65up'\n",
      " 'numbUrban' 'pctUrban' 'medIncome' 'pctWWage' 'pctWFarmSelf' 'pctWInvInc'\n",
      " 'pctWSocSec' 'pctWPubAsst' 'pctWRetire' 'medFamInc' 'perCapInc'\n",
      " 'whitePerCap' 'blackPerCap' 'indianPerCap' 'AsianPerCap' 'HispPerCap'\n",
      " 'NumUnderPov' 'PctPopUnderPov' 'PctLess9thGrade' 'PctNotHSGrad'\n",
      " 'PctBSorMore' 'PctUnemployed' 'PctEmploy' 'PctEmplManu' 'PctEmplProfServ'\n",
      " 'PctOccupManu' 'PctOccupMgmtProf' 'MalePctDivorce' 'MalePctNevMarr'\n",
      " 'FemalePctDiv' 'TotalPctDiv' 'PersPerFam' 'PctFam2Par' 'PctKids2Par'\n",
      " 'PctYoungKids2Par' 'PctTeen2Par' 'PctWorkMomYoungKids' 'PctWorkMom'\n",
      " 'NumKidsBornNeverMar' 'PctKidsBornNeverMar' 'NumImmig' 'PctImmigRecent'\n",
      " 'PctImmigRec5' 'PctImmigRec8' 'PctImmigRec10' 'PctRecentImmig'\n",
      " 'PctRecImmig5' 'PctRecImmig8' 'PctRecImmig10' 'PctSpeakEnglOnly'\n",
      " 'PctNotSpeakEnglWell' 'PctLargHouseFam' 'PctLargHouseOccup'\n",
      " 'PersPerOccupHous' 'PersPerOwnOccHous' 'PersPerRentOccHous'\n",
      " 'PctPersOwnOccup' 'PctPersDenseHous' 'PctHousLess3BR' 'MedNumBR'\n",
      " 'HousVacant' 'PctHousOccup' 'PctHousOwnOcc' 'PctVacantBoarded'\n",
      " 'PctVacMore6Mos' 'MedYrHousBuilt' 'PctHousNoPhone' 'PctWOFullPlumb'\n",
      " 'OwnOccLowQuart' 'OwnOccMedVal' 'OwnOccHiQuart' 'OwnOccQrange' 'RentLowQ'\n",
      " 'RentMedian' 'RentHighQ' 'RentQrange' 'MedRent' 'MedRentPctHousInc'\n",
      " 'MedOwnCostPctInc' 'MedOwnCostPctIncNoMtg' 'NumInShelters' 'NumStreet'\n",
      " 'PctForeignBorn' 'PctBornSameState' 'PctSameHouse85' 'PctSameCity85'\n",
      " 'PctSameState85' 'LandArea' 'PopDens' 'PctUsePubTrans'\n",
      " 'LemasPctOfficDrugUn' 'nonViolPerPop']\n",
      "\n",
      "The number of variables : 102\n",
      "\n",
      "The number of observations : 2118\n"
     ]
    }
   ],
   "source": [
    "print(community.columns.values) #Looking at the variables we wil be working with\n",
    "print(\"\\nThe number of variables : {}\".format(len(community.columns.values)))\n",
    "print(\"\\nThe number of observations : {}\".format(len(community)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining X and Y variables we will be using in our model\n",
    "X=community.copy()\n",
    "del X['nonViolPerPop']\n",
    "y=community['nonViolPerPop'].copy() # response variable is the number of non-violent crimes per population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The aim of this notebook is to implement different validation methods and compare their performances using the crime rate data from different communities. We will be using a Lasso regression model to predict the total number of non-violent crimes per population. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will performing Lasso regression using the below three validation methods and determine the best hyperparameters\n",
    "\n",
    "### 1. Train / validation / test split.\n",
    "### 2. 5-Fold cross validation.\n",
    "### 3. 10-Fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start with splitting the data into train valid and test. We will be using 30% of the data as our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.2857, random_state = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "alphas = np.logspace(-10,10,21) # lambda values\n",
    "max_iters = np.arange(50,75,5) # Setting the min and max number of iteration we want the model to run\n",
    "tols = np.linspace(0.0001,0.1,5) # tolerance for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Train / validation / test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trios in total: 525\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_trio=list(itertools.product(alphas,max_iters,tols)) #Forming all possible combinations for accuracy, max iterations and tolerance defined ranges\n",
    "print(\"The number of trios in total: {}\".format(len(hyperparameter_trio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data\n",
    "scaler=StandardScaler() # Instantiate\n",
    "scaler.fit(X_train) # Fitting the data\n",
    "X_train=pd.DataFrame(scaler.transform(X_train)) # transforming the data\n",
    "X_valid=pd.DataFrame(scaler.transform(X_valid)) # transforming the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_Scores=[]\n",
    "# performing lasso regression on all the hyperparameter trios. Fit in the training data and predicting the validation set and finding MSE\n",
    "start = datetime.now()\n",
    "for a in hyperparameter_trio:\n",
    "    lm_trainlasso=linear_model.Lasso(alpha=a[0],max_iter=a[1],tol=a[2])\n",
    "    lm_trainlasso.fit(X_train,y_train)\n",
    "    Validation_Scores.append(metrics.mean_squared_error(lm_trainlasso.predict(X_valid),y_valid))\n",
    "end = datetime.now() \n",
    "M1 = end - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerror_M1 = min(Validation_Scores) # min validation misclassification error\n",
    "besttrio_M1 = hyperparameter_trio[np.argmin(Validation_Scores)] #finding the hyperparameter trio that gives least error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best trio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyperparameter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tol</th>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Best trio\n",
       "Hyperparameter           \n",
       "alpha              1.0000\n",
       "max_iter          50.0000\n",
       "tol                0.0001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the hyperparameter trio (alpha,max iteration,tolerance) with the lowest mean squared errors\n",
    "bestparam_M1 = pd.DataFrame(zip(['alpha','max_iter','tol'], besttrio_M1))\n",
    "bestparam_M1 = bestparam_M1.rename(columns = {0:'Hyperparameter', 1:'Best trio'})\n",
    "bestparam_M1 = bestparam_M1.set_index('Hyperparameter')\n",
    "bestparam_M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_valid)\n",
    "X_train_valid = pd.DataFrame(scaler.transform(X_train_valid))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test)) # transforming the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vars</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>-191.307715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>householdsize</th>\n",
       "      <td>-262.531808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racepctblack</th>\n",
       "      <td>271.710957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctWhite</th>\n",
       "      <td>286.458009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctAsian</th>\n",
       "      <td>89.959975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coef\n",
       "Vars                     \n",
       "population    -191.307715\n",
       "householdsize -262.531808\n",
       "racepctblack   271.710957\n",
       "racePctWhite   286.458009\n",
       "racePctAsian    89.959975"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit model with train + validation set, perform prediction on test set\n",
    "lm1 = linear_model.Lasso(alpha = besttrio_M1[0], max_iter = besttrio_M1[1], tol = besttrio_M1[2])\n",
    "lm1.fit(X_train_valid, y_train_valid)\n",
    "d1 = pd.DataFrame(zip(X.columns.values, lm1.coef_))\n",
    "d1 = d1.rename(columns = {0:'Vars', 1:'Coef'})\n",
    "d1 = d1.set_index('Vars')\n",
    "d1.head() #printing the first 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction error for the test set is : 3539035.5943705086\n"
     ]
    }
   ],
   "source": [
    "M1_terror = metrics.mean_squared_error(lm1.predict(X_test),y_test)\n",
    "print(\"The prediction error for the test set is : {}\".format(M1_terror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: 5-Fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "estimator = Pipeline([('scale', StandardScaler()), ('lasso',Lasso())]) # setting up model pipeline\n",
    "parameters = {'lasso__alpha':alphas, 'lasso__max_iter':max_iters, 'lasso__tol':tols}#Adding the three hyperparameters\n",
    "lm2 = GridSearchCV(estimator = estimator, param_grid = parameters, cv = 5, scoring = 'neg_mean_squared_error', n_jobs = -1) \n",
    "lm2.fit(X_train_valid, y_train_valid) # fitting train+valid\n",
    "end = datetime.now()\n",
    "M2 = end - start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best hyperparameter trio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best trio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyperparameter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso__alpha</th>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso__max_iter</th>\n",
       "      <td>65.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso__tol</th>\n",
       "      <td>0.05005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Best trio\n",
       "Hyperparameter            \n",
       "lasso__alpha      10.00000\n",
       "lasso__max_iter   65.00000\n",
       "lasso__tol         0.05005"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the hyperparameter trio (alpha,max iteration,tolerance) with the lowest mean squared error\n",
    "bestparam_M2 = pd.DataFrame(zip(parameters.keys(), lm2.best_params_.values()))\n",
    "bestparam_M2 = bestparam_M2.rename(columns = {0:'Hyperparameter', 1:'Best trio'})\n",
    "bestparam_M2 = bestparam_M2.set_index('Hyperparameter')\n",
    "bestparam_M2 # the best parameter from CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction error for the test set is : 3476161.6429157713\n"
     ]
    }
   ],
   "source": [
    "M2_terror = metrics.mean_squared_error(lm2.predict(X_test), y_test) # prediction on test test\n",
    "print(\"The prediction error for the test set is : {}\".format(M2_terror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vars</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>householdsize</th>\n",
       "      <td>-257.075396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racepctblack</th>\n",
       "      <td>87.032575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctWhite</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctAsian</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coef\n",
       "Vars                     \n",
       "population      -0.000000\n",
       "householdsize -257.075396\n",
       "racepctblack    87.032575\n",
       "racePctWhite     0.000000\n",
       "racePctAsian     0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = pd.DataFrame(zip(X.columns.values, lm2.best_estimator_.named_steps['lasso'].coef_))\n",
    "d2 = d2.rename(columns = {0:'Vars', 1:'Coef'})\n",
    "d2 = d2.set_index('Vars')\n",
    "d2.head() #printing the first 5 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: 10-Fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "estimator = Pipeline([('scale', StandardScaler()), ('lasso',Lasso())]) # Model Pipeline\n",
    "parameters = {'lasso__alpha':alphas, 'lasso__max_iter':max_iters, 'lasso__tol':tols}\n",
    "lm3 = GridSearchCV(estimator = estimator, param_grid = parameters, cv = 10, scoring = 'neg_mean_squared_error', n_jobs = -1) \n",
    "lm3.fit(X_train_valid, y_train_valid) \n",
    "end = datetime.now()\n",
    "M3 = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best hyperparameter trio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best trio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyperparameter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso__alpha</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso__max_iter</th>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso__tol</th>\n",
       "      <td>0.025075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Best trio\n",
       "Hyperparameter            \n",
       "lasso__alpha     10.000000\n",
       "lasso__max_iter  70.000000\n",
       "lasso__tol        0.025075"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the hyperparameter trio (alpha,max iteration,tolerance) with the lowest mean squared errors\n",
    "bestparam_M3 = pd.DataFrame(zip(parameters.keys(), lm3.best_params_.values()))\n",
    "bestparam_M3 = bestparam_M3.rename(columns = {0:'Hyperparameter', 1:'Best trio'})\n",
    "bestparam_M3 = bestparam_M3.set_index('Hyperparameter')\n",
    "bestparam_M3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction error for the test set is : 3473558.939727634\n"
     ]
    }
   ],
   "source": [
    "M3_terror = metrics.mean_squared_error(lm3.predict(X_test), y_test) # prediction on test test\n",
    "print(\"The prediction error for the test set is : {}\".format(M3_terror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vars</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>householdsize</th>\n",
       "      <td>-258.593448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racepctblack</th>\n",
       "      <td>88.166913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctWhite</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctAsian</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coef\n",
       "Vars                     \n",
       "population      -0.000000\n",
       "householdsize -258.593448\n",
       "racepctblack    88.166913\n",
       "racePctWhite     0.000000\n",
       "racePctAsian     0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = pd.DataFrame(zip(X.columns.values, lm3.best_estimator_.named_steps['lasso'].coef_))\n",
    "d3 = d3.rename(columns = {0:'Vars', 1:'Coef'})\n",
    "d3 = d3.set_index('Vars')\n",
    "d3.head() #printing the first 5 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the three methods (M1,M2,M3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by each model to run:\n",
      "\n",
      "   Method            Time\n",
      "0     M1 00:00:25.351023\n",
      "1     M2 00:04:31.204233\n",
      "2     M3 00:09:41.683957\n",
      "\n",
      "Minimum time taken:\n",
      "\n",
      "   Method            Time\n",
      "0     M1 00:00:25.351023\n"
     ]
    }
   ],
   "source": [
    "Methodname = ['M1','M2','M3']\n",
    "Mintime = [M1, M2, M3]\n",
    "d4 = pd.DataFrame(zip(Methodname, Mintime))\n",
    "d4 = d4.rename(columns = {0:'Method', 1:'Time'})\n",
    "print('Time taken by each model to run:\\n\\n', d4)\n",
    "\n",
    "# calculating the model which is taking minimum time\n",
    "mintime = d4[['Method','Time']][d4['Time'] == d4['Time'].min()] \n",
    "print('\\nMinimum time taken:\\n\\n', mintime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Method 1 takes the least amount of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Hyperparameter trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_iter</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tol</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.05005</td>\n",
       "      <td>0.025075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hyperparameters       M1        M2         M3\n",
       "0           alpha   1.0000  10.00000  10.000000\n",
       "1        max_iter  50.0000  65.00000  70.000000\n",
       "2             tol   0.0001   0.05005   0.025075"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triocomp=pd.DataFrame(zip(['alpha','max_iter','tol'], besttrio_M1,lm2.best_params_.values(),lm3.best_params_.values()))\n",
    "triocomp=triocomp.rename(columns={0:'Hyperparameters',1:'M1',2:'M2',3:'M3'})\n",
    "triocomp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The best alpha value is 10 for both M2 and M3. The number of iteration is the most for method 3 and least for method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Mean squared error comparison (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of three methods:\n",
      "   Method           MSE\n",
      "0     M1  3.539036e+06\n",
      "1     M2  3.476162e+06\n",
      "2     M3  3.473559e+06\n",
      "\n",
      "Minimum error:\n",
      "   Method           MSE\n",
      "2     M3  3.473559e+06\n"
     ]
    }
   ],
   "source": [
    "Minerror = [M1_terror, M2_terror, M3_terror]\n",
    "d5 = pd.DataFrame(zip(Methodname, Minerror))\n",
    "d5 = d5.rename(columns = {0:'Method', 1:'MSE'})\n",
    "print('MSE of three methods:\\n', d5)\n",
    "\n",
    " # calculating the model with least MSE\n",
    "minerror = d5[['Method','MSE']][d5['MSE'] == d5['MSE'].min()]\n",
    "print('\\nMinimum error:\\n', minerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Least error on the test set is given by method 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Coefficient comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1\n",
      "                             Coef\n",
      "Vars                            \n",
      "PersPerOccupHous     1057.493663\n",
      "PctForeignBorn        831.529309\n",
      "NumKidsBornNeverMar   744.253307\n",
      "MalePctNevMarr        737.867836\n",
      "PersPerOwnOccHous     669.837470\n",
      "\n",
      "Model_2\n",
      "                         Coef\n",
      "Vars                        \n",
      "PctForeignBorn    694.631090\n",
      "PersPerOccupHous  615.307836\n",
      "MalePctNevMarr    547.458027\n",
      "PctPopUnderPov    533.548267\n",
      "PctKids2Par       511.629813\n",
      "\n",
      "Model_3\n",
      "                         Coef\n",
      "Vars                        \n",
      "PctForeignBorn    750.458970\n",
      "PctKids2Par       593.013168\n",
      "PersPerOccupHous  581.750552\n",
      "MalePctNevMarr    562.973969\n",
      "PctPopUnderPov    477.270452\n",
      "Index(['population', 'racePctWhite', 'racePctAsian', 'racePctHisp',\n",
      "       'agePct65up', 'numbUrban', 'medIncome', 'pctWWage', 'perCapInc',\n",
      "       'NumUnderPov', 'PctOccupManu', 'PersPerFam', 'PctYoungKids2Par',\n",
      "       'PctTeen2Par', 'PctWorkMomYoungKids', 'NumImmig', 'PctImmigRec8',\n",
      "       'PctRecImmig5', 'PctRecImmig10', 'PctNotSpeakEnglWell',\n",
      "       'PctLargHouseFam', 'PctHousLess3BR', 'PctHousOwnOcc',\n",
      "       'PctVacantBoarded', 'OwnOccHiQuart', 'OwnOccQrange', 'RentMedian',\n",
      "       'MedRent', 'NumStreet', 'PctSameHouse85'],\n",
      "      dtype='object', name='Vars')\n",
      "Index(['agePct12t21', 'medFamInc'], dtype='object', name='Vars')\n"
     ]
    }
   ],
   "source": [
    "# Taking the absolute values of coefficients and printing the top five for each in descending order \n",
    "\n",
    "# Method 1\n",
    "d1['Coef'] = abs(d1['Coef'].values)\n",
    "print('Model_1\\n', d1.sort_values(by='Coef', ascending=False).head())\n",
    "\n",
    "# Method 2\n",
    "d2['Coef'] = abs(d2['Coef'].values)\n",
    "print('\\nModel_2\\n', d2.sort_values(by = 'Coef', ascending=False).head())\n",
    "\n",
    "# Method 3\n",
    "d3['Coef'] = abs(d3['Coef'].values)\n",
    "print('\\nModel_3\\n', d3.sort_values(by = 'Coef', ascending=False).head())\n",
    "\n",
    "# Common/Uncommon features shrinked by each model\n",
    "common_features = d2[d2['Coef'] == 0].index & d3[d3['Coef'] == 0].index\n",
    "print(common_features)\n",
    "\n",
    "uncommon_features = d2[d2['Coef'] == 0].index.symmetric_difference(d3[d3['Coef'] == 0].index)\n",
    "print(uncommon_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We have taken the absolute values of the coefficients here in descending order to determine the best coefficient according to every model.\n",
    "###### Shrinkage: We compared Model_2 and Model_3 only since Model_1 shrinked only one feature which is 'PctEmplProfServ' which was not present in M2 and M3 when we looked for shrinked features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features shrinked to zero by M1: 1\n",
      "Total features shrinked to zero by M2: 30\n",
      "Total features shrinked to zero by M3: 32\n"
     ]
    }
   ],
   "source": [
    "# counting the number of features shrinked to zero\n",
    "print('Total features shrinked to zero by M1:', d1[d1['Coef']==0].count(axis=1).sum())\n",
    "print('Total features shrinked to zero by M2:', d2[d2['Coef'] == 0].count(axis = 1).sum())\n",
    "print('Total features shrinked to zero by M3:', d3[d3['Coef'] == 0].count(axis = 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Method 1: Out of 101 predictors, this is able to shrink only one feature to zero.\n",
    "###### Method 2: This model seems to be give better results than the previous as it is shrinking 30 features to zero.\n",
    "###### Method 3: This performs evern better as it is able to shrink 32 useless features to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "\n",
    "Time: \n",
    "The least time taken is by M1 and M3 takes the maximum time. This makes absolute sense as more the number of folds, more is the time taken by the model.\n",
    "\n",
    "Mean squared error:\n",
    "Among M1,M2 and M3- M3 has the lowest MSE which means M3 is giving us the most accurate prediction results.\n",
    "\n",
    "Coefficients: \n",
    "If we compare the top five coefficients among all the three models, it can be observed that 'PctForeignBorn, PersPerOccupHous and MalePctNevMarr' are the predictors which are in the top list for all the three models.\n",
    "\n",
    "Shrinkage: \n",
    "M1: 1, M2: 30, M3: 32\n",
    "We can see that M1 is shrinking only 1 feature to zero, whereas M2 and M3 are shrinking 30 and 32 features respectively.\n",
    "So, with respect to shrinkage, we can say that M3 would be the least complicated method since it has less features. Scoring will be much faster for M2 and M3.\n",
    "\n",
    "There is not much difference in MSE of M2 and M3(the difference starts at third decimal place) but the time taken by M3 is almost 2.5 times more than M2, so if time is a major factor for us, then we should go ahead with M2 model.\n",
    "\n",
    "If time is not a major factor, for this high dimensional data, we would select M3 Model as it is screening out the most number of useless features making it simplest among all the three models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pros and cons of the 3 methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In train/valid/test split method, we may encounter a problem if the data is not split at random. We may end up overfitting the model. Athough this is more of a problem for train/test split method. We reduce the chances by including the extra validation step. Pros would be that when time is a major factor, this method takes lesser time as compared to CV\n",
    "\n",
    "\n",
    "The risk of running a 10 fold CV is that if we have a small sample size, there are chances of getting duplicates. So it is better to use 10 fold CV when we have a larger data set. Also, more training samples usually means that we are at a flatter part of the learning curve, so the difference between the surrogate models and the \"real\" model trained on all n samples becomes negligible.\n",
    "If the slope of the learning curve is flat enough at say training_size = 90% of total dataset, then the bias can be ignored and K=10 is reasonable.\n",
    "\n",
    "High K means more folds, thus higher computational time and vice versa. Also higher K gives more samples to estimate a more accurate confidence interval on our estimate\n",
    "\n",
    "Lower the K means lower the variance and higher the bias. Higher the K means higher the variance and lower the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
